#!/usr/bin/python3.11
"""Normalize names of files.

Renames files in a directory according to a file of canonical file name stubs."""
# TODO - use shutil term width to print better rename summary

from __future__ import annotations

import re
import os
import sys
import time
import json
import hashlib
import filecmp
import tomllib
import argparse
from pathlib import Path
from datetime import datetime, timezone
from dataclasses import dataclass

class Constants:
    progname = "nomnorm"
    version = "1.2"
    config_file = f"{progname}.config.toml"
    config_file_path = Path.home() / ".config" / progname / config_file
    dir_config = f".{config_file}"
    # if the file mtime is outside this epsilon, we fix it
    mtime_epsilon_seconds = 2

    # Note this string is split into an f-string part for progname etc,
    # and a non-f-string with settings and descriptions having many {}.
    default_config: str = f"""\
# {progname} configuration toml file
#
# First generated {datetime.now()} by {progname} version {version}
# For information on toml syntax, see https://toml.io/en/
""" """\
profile = "default"

[default]
# Name of file containing the final filename stubs
stubs_file = "filename_stubs.txt"

# match_groups is a table specifying groups common to many of the file_subs
# and/or the stub_pattern. Each pattern is formatted by calling
# .format(**match_groups) on it to replace instance of {groupname} in the
# pattern with the value of match_groups.groupname in this table.
# However, first, each substitution is wrapped with the name of the key, so
# each resulting group match pattern is a named group.
match_groups.key = '\d{8}-\d{6}'
match_groups.resmp4 = '\d+x\d+\.mp4'

# stub_pattern is used to extract the key and replacement text from the
# filename stubs in stubs_file.
#
# The pattern must contain a group named 'key', which is used as a hash key in
# the dict for looking up which replacement to use for each file matched by
# patterns in the src_pattern array.
#
# The entire text of the matched stub is passed as a keyword parameter named
# 'stub' to the format call for renaming the src files, so the pattern need
# not match more than the key group in the pattern.
#
# The pattern text can contain named match groups.  These are passed as
# keyword arguments to format the replacement text.
stub_pattern = 'zoom[._]{key}(GMT|Z).*'

# file_subs is a list of inline dicts, each with two keys:
#
# * pat - regex pattern used to match each filename; must contain the 'key' named group
#   Each pattern has .format() called on it with keywords from match_groups
#   and 'stub_pattern' defined.  The values of match_groups are substituted
#   directly, but the stub_pattern is first itself formatted using the
#   match_groups. To use {} range matching, you will need to double the braces
#   to avoid the format expansion like {{ }}.
#
# * rep - replacement template.  This can contain back-references as well as
#   {} format interpolation parts, since .format() is called on this string
#   with the following keyword parameters:
#   - 'stub' - the text of the filename stub this filename's key matched in the stubs_file
#   - any of the named groups matched from the stub_pattern
#
# For each file, each pattern in this list is tried in order - the first one
# that matches is applied to determine how to match the key and rename the file.
#
# TODO - we could another entry called 'key' that specifies how to form the
# key from the given pattern, allowing key renaming.
file_subs = [
  { pat='{stub_pattern}[_.]{resmp4}', rep='{stub}.\g<resmp4>' },
  { pat='{stub_pattern}[_.]?(newChat)?\.txt', rep='{stub}.chat.txt' },
  { pat='{stub_pattern}\.m4a', rep='{stub}.m4a' },
  { pat='GMT{key}_Recording_{resmp4}', rep='{stub}.\g<resmp4>' },
  { pat='GMT{key}_Recording(newChat)?.txt', rep='{stub}.chat.txt' },
  { pat='GMT{key}_Recording.m4a', rep='{stub}.m4a' },
]

# When true, the script uses the parsed timestamp as a GMT timestamp, and
# updates the file's last-update (modification) time to match.
mtime.enable = true

# {}-style format string from which the time will be parsed.
# This can use the match groups from pat entries in the file_subs list,
# as long as the group is present across all pat entries in file_subs.
mtime.source = "{key}"

# strftime-style interpolation string for strptime parsing
mtime.strpfmt = "%Y%m%d-%H%M%S"
"""

class NomnormConfigKeyError(KeyError): pass
class NomnormConflictError(KeyError): pass

class ConfigDict(dict):
    """Class for storing configuration options, allowing easy access via dot notation.

    This makes reasonable sense because config options aren't expected to be arbitrary
    objects, but rather predefined strings.

    Read accesses to keys in ConfigDict instances should be done via attribute access
    only, allowing the machinery to print the path to the key if a key is missing in
    a config file.  This path is tracked through the _context key in each ConfigDict,
    built via the attrify() method.

    ConfigDict instances created without attrify should init the _context key
    appropriately to set the root of the context path for error reporting.
    """
    def __getattr__(self, key):
        try:
            return self[key]
        except KeyError:
            raise NomnormConfigKeyError(
                f"key '{key}' not found in config {self.get('_context', '<unknown')}")

    @staticmethod
    def attrify(struct: list|dict|Any, context: str) -> list|ConfigDict|Any:
        """Walks the given list/dict struct and returns a ConfigDict-ified one.

        The returned struct is identical except all dict-like instances are
        replaced with new shallow copies as ConfigDict instances.

        Additionally, each ConfigDict's _context field is filled in automatically
        with its path starting from the given context argument, allowing
        attempts to access unknown keys via attributes to include that path
        in the raised NomnormConfigKeyError.
        """
        if isinstance(struct, dict):
            return ConfigDict(
                ((k, ConfigDict.attrify(v, context=f"{context}:{k}"))
                 for k, v in struct.items()),
                _context=context)
        elif isinstance(struct, list):
            return [ConfigDict.attrify(e, context=f"{context}[{i}]")
                    for i, e in enumerate(struct)]
        else:
            return struct

def update_recursive(struct, overrides):
    """\
    When struct is a dict, we can recurse into it and set keys.
    In this case, overrides must also be a dict - it structure must
    match.  We iterate only over the keys in overrides to do the
    replacements.

    If struct[k] exists, we need to recurse into it.
    Otherwise, we just set struct[k] = v
    """
    if isinstance(struct, dict):
        for k, v in overrides.items():
            # If k not in struct, we'll call update_recursive(None, v) which returns v
            struct[k] = update_recursive(struct.get(k), v)
    else:
        # Completely replace the struct if it's not a dict to recurse into
        struct = overrides
    return struct

class ConfigFile:
    """Class for managing toml configs files.

    The loaded config is in the config data member, with all dicts replaced
    with ConfigDict instances.
    """
    def __init__(self, default: str="") -> None:
        self.default = default
        self.config: ConfigDict = ConfigDict(_context='uninitialized')

    def load_file(self, path: Path|str) -> None:
        """Loads a config from the path overriding anything in the current config."""
        with open(path, "rb") as f:
            overrides = ConfigDict.attrify(tomllib.load(f), context=str(path))
        self.config = update_recursive(self.config, overrides)

    def load_default(self) -> object:
        """Just load the default config, don't mess with the config file"""
        self.config = ConfigDict.attrify(tomllib.loads(self.default), context="<default>")

    def regenerate_config(self, path) -> object:
        self.rename_config_to_backup(path)
        self.write_default_config(path)

    @staticmethod
    def rename_config_to_backup(path: Path|str) -> None:
        path = Path(path)
        if not path.exists():
            return

        # Get the last modification time of the file
        mtime = path.stat().st_mtime
        timestamp = datetime.utcfromtimestamp(mtime).strftime("%Y%m%dT%H%M%S")

        # Rename the file
        new_path = path.with_name(f"{path.stem}.old.{timestamp}{path.suffix}")
        path.rename(new_path)

        print(f"Previous config file backed up to: {new_path}")

    def write_default_config(self, path: str|Path) -> object:
        with open(path, mode='x') as f:
            f.write(self.default)

    def print(self):
        """Prints the config as json for debug"""
        json.dump(self.config, sys.stdout, indent=1)

@dataclass
class FileInfo:
    source: str
    dest: str
    dest_exists: bool
    set_mtime: bool = False
    source_mtime: int|float|None = None
    target_mtime: int|float|None = None

def load_stubs(dir: str|Path, stubs_file: str) -> list[str]:
    """Loads the canonical stub names for normalization and returns a list of them.

    Whitespace surrounding each stub name is ignored.
    Blank lines and lines starting with # (preceded by optional whitespace) are ignored.
    """
    has_slash =  "/" in stubs_file or "\\" in stubs_file
    with open(stubs_file if has_slash else Path(dir)/stubs_file, "r") as f:
        return [name for name in (line.strip() for line in f)
                if name and not name.startswith("#")]

def prepare_regex_matchers(match_groups: ConfigDict|None,
                           stub_pattern: str,
                           file_subs: list[dict[str, str]]) -> callable:
    """Processes match_groups to compile the needed regexes.

    Injects the resulting file_sub matching re.match() functions into the
    file_subs dicts under keyword 'match', and returns the re.match
    for matching the file stub names.
    """
    match_groups = match_groups or {}
    group_kwargs = {k: f"(?P<{k}>{v})" for k, v in match_groups.items()}

    # Compile the regexes
    stub_pat_expanded = stub_pattern.format(**group_kwargs)
    for d in file_subs:
        d['match'] = re.compile(d.pat.format(stub_pattern=stub_pat_expanded,
                                             **group_kwargs)).match
    return re.compile(stub_pat_expanded).match

def extract_stub_keys(stub_match: callable,
                      stubs: list[str]) -> dict[str, str]:
    """Extracts the 'key' group from each stub using stub_match.
    Returns a dict mapping each key to its stub.
    """
    key_stub_map = {}
    for stub in stubs:
        if m := stub_match(stub):
            key_stub_map[m['key']] = stub
    return key_stub_map

def scan_dir(dir: Path|str,
             file_subs: list[dict[str, str]],
             key_stub_map: dict[str, str],
             mtime_config: ConfigDict) -> list[FileInfo]:
    """Scans the given dir for files to rename and mtime-adjust.

    Prints a summary of the changes that will be made,
    and returns a list of FileInfo objects describing the changes.
    """
    dir = Path(dir)
    unmatched_files = []
    used_stubs = set()
    renames: list[FileInfo] = []
    existing_conflicts = set()
    dest_fi_map: dict[str, list(FileInfo)] = {} # for tracking destination conflicts
    # scan all files in dir
    for fname in sorted(os.listdir(dir)):
        # fname is just the basename, dir is not prepended
        # Try to match each file_subs pattern to set up the rename
        for file_sub in file_subs:
            if m := file_sub.match(fname):
                if stub := key_stub_map.get(m['key']):
                    used_stubs.add(stub)
                    # Formulate the normalized filename from the stub
                    newname = m.re.sub(file_sub.rep.format(stub=stub), m.string)

                    renames.append(fi := FileInfo(
                        source=fname,
                        dest=newname,
                        dest_exists=(dir / newname).exists(),
                    ))
                    dest_fi_map.setdefault(newname, []).append(fi)

                    # Gather the mtimes
                    if mtime_config and mtime_config.enable:
                        t = datetime.strptime(
                            mtime_config.source.format(**m.groupdict()),
                            mtime_config.strpfmt)
                        t = t.replace(tzinfo=timezone.utc)
                        fi.target_mtime = t.timestamp()

                        fi.source_mtime=os.path.getmtime(dir / fname)
                        fi.set_mtime = abs(fi.target_mtime - fi.source_mtime) \
                                       >= Constants.mtime_epsilon_seconds

                    if fi.dest_exists and newname != fname:
                        existing_conflicts.add(fname)

                    break
        else:
            unmatched_files.append(fname)

    # Explain what we're going to do
    if unmatched_files:
        print(f"> Unmatched files:")
        for file in unmatched_files:
            print(" ", file)

    unmatched_stubs = set(key_stub_map.values()) - used_stubs
    summary = (f"{len(renames)} file(s),"
               f" {len([k for k, v in dest_fi_map.items() if len(v) > 1])}"
               f" dest name conflict(s),"
               f" {len(existing_conflicts)} existing dest conflict(s),"
               f" {len(unmatched_stubs)} unmatched stub(s),"
               f" {len(unmatched_files)} unmatched file(s)")
    print(summary)
    for stub in sorted(unmatched_stubs):
        print(f" - Unmatched stub: {stub}")
    for fi in renames:
        #msg = "[target exists] " if fi.dest_exists else ""
        #print(f"{msg}{old}  ->  {new}")
        eq = fi.source == fi.dest
        if fi.set_mtime or not eq:
            print(f"{fi.source}"
                  f"""{'' if eq else f' {"XX" if fi.dest_exists else "->"} {fi.dest}'}"""
                  f"{'  [setting mtime]' if fi.set_mtime else ''}")
        #else: print(f"< skipping {fi.source}")

    check_for_conflicts(dir, dest_fi_map)
    return renames

def check_for_conflicts(dir: Path, dest_fi_map: dict[str, list[FileInfo]]) -> None:
    """Searches for conflicting file contents for each set of renames.

    If conflicts are found, they are all printed, and an exception is raised.
    """
    def sha256(name):
        """Returns the sha256 of the contents of the file at dir/name"""
        with open(dir / name, 'rb') as f:
            return hashlib.file_digest(f, 'sha256').hexdigest()

    # Gather sha256s for any foreseeable conflict
    should_abort = False
    for dest, fileinfos in dest_fi_map.items():
        fi0 = fileinfos[0]
        if len(fileinfos) > 1 or (fi0.dest_exists and fi0.source != fi0.dest):
            # Rename conflicts exist for this dest; check hashes of all
            shamap: dict[str, set[str]] = {}
            if fileinfos[0].dest_exists:
                shamap.setdefault(sha256(dest), set()).add(dest)

            for fi in fileinfos:
                assert fi.dest == dest
                if fi.source != dest:
                    shamap.setdefault(sha256(fi.source), set()).add(fi.source)

            # Summarize the dict of sha(s)
            if len(shamap) > 1:
                # we have mismatching contents!
                should_abort = True
                print(f"\nConflict: Multiple distinct files would map to '{dest}'")
                for sha, names in shamap.items():
                    for name in names: break  # get a name for getsize-ing
                    size = os.path.getsize(dir / name)
                    print(f"* {sha} {size:14,} bytes:")
                    for name in sorted(names):
                        print(f"  > {name}{' (target)'}")

    if should_abort:
        raise NomnormConflictError(
            "error: Renames exist between files with mismatching contents")

def process_renames_and_mtimes(dir: Path|str, renames: list[FileInfo]) -> None:
    """Performs the requested renames and mtime adjustments in dir.

    Prints a character representing each file processed:
     . - file renamed
     X - file deleted due to identical contents
     s - renamed skipped due to destination file existing with different contents
     T - mtime updated
     t - mtime update was planned, but dest already existed with the correct mtime
    """
    dir = Path(dir)
    skipped = []
    for fi in renames:
        spath = dir / fi.source
        dpath = dir / fi.dest

        if fi.source != fi.dest:
            if fi.dest_exists:
                if filecmp.cmp(spath, dpath, shallow=False):
                    # Contents match, delete the source instead of renaming it
                    os.remove(spath)
                    print('X', end='')
                else:
                    skipped.append(fi)
                    print('s', end='')
            else:
                os.rename(spath, dpath)
                print('.', end='')
            sys.stdout.flush()

        really_set_mtime = abs(fi.target_mtime - os.path.getmtime(dpath)) \
                           >= Constants.mtime_epsilon_seconds
        if really_set_mtime:
            os.utime(dpath, times=(time.time(), fi.target_mtime))
            print('T', end='')
            sys.stdout.flush()
        elif fi.set_mtime:
            print('t', end='')
            sys.stdout.flush()

    print()
    if skipped:
        print(f"\n*** WARNING: {len(skipped)} file(s) would have overwritten"
              f" their destination but have different contents! ***")
    for fi in skipped:
        print(f"* '{fi.source}' != '{fi.dest}'")

def process_dir(dir: str|Path,
                act: bool,
                cfg: ConfigDict):
    """Renames files in dir according to the given config."""
    stubs = load_stubs(dir, cfg.stubs_file)
    stub_match = prepare_regex_matchers(cfg.match_groups, cfg.stub_pattern, cfg.file_subs)
    key_stub_map = extract_stub_keys(stub_match, stubs)
    renames = scan_dir(dir, cfg.file_subs, key_stub_map, cfg.mtime)
    if act:
        process_renames_and_mtimes(dir, renames)

def extract_profile(cf: ConfigDict, opts: argparse.ArgumentParser) -> ConfigDict:
    # Load the main config file
    if not opts.config:
        if Constants.config_file_path.exists():
            cf.load_file(Constants.config_file_path)
        else:
            cf.load_default()

    elif opts.config != "-":
        cf.load_file(opts.config)

    # Load the sub-config file from the target dir
    subconfig = Path(opts.dir) / opts.dir_config
    if subconfig.exists():
        cf.load_file(subconfig)

    # Set opts.profile from the config if --profile wasn't on the command line
    if opts.profile is None:
        opts.profile = cf.config.profile

    # Extract the selected config profile and override its stubs_file if requested
    profile = getattr(cf.config, opts.profile)
    if opts.stubs_file is not None:
        profile["stubs_file"] = opts.stubs_file

    return profile

def process_command_line() -> argparse.Namespace:
    """Load the command line options"""
    parser = argparse.ArgumentParser(
        prog=Constants.progname,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=__doc__,
        epilog="",
    )
    parser.add_argument('dir', nargs="?", default=".",
                        help="target directory of files to process")
    parser.add_argument('-c', '--config',
                        help=f"""main .toml config file to load.
                        Set to - to avoid loading any main config.
                        default: {Constants.config_file_path}""")
    parser.add_argument('-d', '--dir-config', default=Constants.dir_config,
                        help=f"""file name of the override config file to load from the dir.
                        Set to - to avoid loading any config from the target dir.
                        It's expected that this config file will only override the profile.""")
    parser.add_argument('-p', '--profile',
                        help="""the profile to select form the config file.
                        This overrides both the --config file and the --dir-config.""")
    parser.add_argument('-s', '--stubs-file',
                        help="""filename of the cononical stub names used for renaming.
                        If this contains no path separators, it's resolved in the target dir.
                        Otherwise, it's resolved relative to the cwd.
                        To use a file named filename in the current dir, specify ./filename.
                        Defaults to the stubs_file setting in the config.""")
    parser.add_argument('-n', '--no-act', action='store_true',
                        help="don't rename any files, just print what we would have done")
    parser.add_argument('-w', '--write-config', action='store_true',
                        help=f"""write the default config contents to the selected
                        --config file, which may be the default, and exit""")
    parser.add_argument('-V', '--version', action='store_true',
                        help=f"print the version number of {Constants.progname} and exit")
    return parser.parse_args()

def main():
    #config = ConfigFile.regenerate_config()
    opts = process_command_line()
    cf = ConfigFile(default=Constants.default_config)

    if opts.version:
        print(f"{Constants.progname} {Constants.version}")
        return 0

    if opts.write_config:
        cfile = opts.config or Constants.config_file_path
        if cfile == "-":
            print("Error: refusing to write to config file named '-'")
            return 2
        else:
            cf.regenerate_config(cfile)
            return 0

    profile = extract_profile(cf, opts)
    return process_dir(opts.dir, act=not opts.no_act, cfg=profile)

if __name__ == "__main__":
    sys.exit(main())
